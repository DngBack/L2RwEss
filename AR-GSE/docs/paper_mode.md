# Paper Mode Dataset Implementation

ÄÃ¢y lÃ  implementation **paper mode** cho dataset CIFAR-10/100-LT theo yÃªu cáº§u nghiÃªn cá»©u.

## âœ¨ TÃ­nh nÄƒng chÃ­nh

### ğŸ¯ Paper Mode Dataset Structure
- **TRAIN**: Long-tailed CIFAR-10/100 (exponential imbalance)
- **VAL**: 20% tá»« original test set (balanced) 
- **TEST**: 80% tá»« original test set (balanced)
- **Re-weighting**: Trá»ng sá»‘ lá»›p Ä‘á»ƒ cÃ¢n báº±ng train vs test distribution

### ğŸ“Š Class Grouping  
- **Head classes**: > 20 samples (nhiá»u dá»¯ liá»‡u)
- **Tail classes**: â‰¤ 20 samples (Ã­t dá»¯ liá»‡u)
- NgÆ°á»¡ng threshold=20 theo paper specification

### ğŸ”§ Data Sources
- **Torchvision**: Tá»± táº¡o long-tailed tá»« CIFAR chuáº©n
- **HuggingFace**: Load CIFAR-100-LT cÃ³ sáºµn (dá»± kiáº¿n)

## ğŸš€ Quick Start

### 1. Build Dataset Splits

```bash
# CIFAR-100-LT paper mode
python build_paper_cli.py --dataset cifar100 --root ./data --output splits/cifar100_paper.json

# CIFAR-10-LT paper mode  
python build_paper_cli.py --dataset cifar10 --root ./data --output splits/cifar10_paper.json

# Vá»›i HuggingFace source (CIFAR-100 only)
python build_paper_cli.py --dataset cifar100 --source huggingface --output splits/cifar100_hf_paper.json
```

### 2. Load vÃ  Sá»­ dá»¥ng

```python
from src.data.datasets import build_cifar100lt_paper

# Build datasets
datasets_dict, meta = build_cifar100lt_paper(
    root="./data",
    seed=42,
    source="torchvision",  # or "huggingface"
    imb_factor=100.0
)

train_set = datasets_dict['train']  # Long-tailed
val_set = datasets_dict['val']      # 20% balanced test  
test_set = datasets_dict['test']    # 80% balanced test

# Láº¥y re-weighting factors
weights_val = meta['weights_val']   # [N_val] 
weights_test = meta['weights_test'] # [N_test]
class_to_group = meta['class_to_group']  # [C] 0=head, 1=tail
```

### 3. Demo Script

```bash
python example_paper_usage.py --metadata splits/cifar100_paper.json
```

## ğŸ“ Files Structure

```
src/data/
â”œâ”€â”€ datasets.py          # Paper mode functions
â”œâ”€â”€ groups.py           # Class grouping utilities  
â”œâ”€â”€ dataset.py          # Base dataset functions
â””â”€â”€ splits.py           # Original splits script

scripts/
â”œâ”€â”€ build_paper_cli.py   # CLI for building paper splits
â””â”€â”€ example_paper_usage.py  # Demo vÃ  usage example

splits/
â”œâ”€â”€ cifar100_paper.json  # CIFAR-100 paper metadata
â””â”€â”€ cifar10_paper.json   # CIFAR-10 paper metadata
```

## ğŸ” Metadata Format

```json
{
  "val_idx": [6252, 4684, ...],      // Indices cho validation split
  "test_idx": [1234, 5678, ...],     // Indices cho test split  
  "weights_val": [1.2, 0.8, ...],    // Re-weight factors cho val
  "weights_test": [1.1, 0.9, ...],   // Re-weight factors cho test
  "counts_train": [500, 450, ...],   // Sá»‘ samples per class trong train
  "class_to_group": [0, 0, 1, ...],  // 0=head, 1=tail
  "num_classes": 100,
  "source": "torchvision",
  "seed": 42
}
```

## ğŸ“ˆ Statistics Examples

### CIFAR-100-LT (imb_factor=100)
```
Train size: 10899 (long-tailed)
Val size: 2000 (balanced)  
Test size: 8000 (balanced)

Class distribution:
  Head classes: 69 (samples: 21-500)
  Tail classes: 31 (samples: 5-20)
  
Re-weighting range: 0.046 - 4.588
```

### CIFAR-10-LT (imb_factor=100)  
```
Train size: 12408 (long-tailed)
Val size: 2000 (balanced)
Test size: 8000 (balanced)

Class distribution:
  Head classes: 10 (samples: 50-5000)  
  Tail classes: 0 (threshold=20 quÃ¡ tháº¥p)
```

## ğŸ›ï¸ Configuration Options

### CLI Arguments
- `--dataset`: "cifar10" hoáº·c "cifar100"
- `--source`: "torchvision" hoáº·c "huggingface"  
- `--imb-factor`: Exponential imbalance factor (default: 100.0)
- `--seed`: Random seed (default: 42)
- `--root`: Data directory (default: "./data")
- `--output`: Output JSON path

### Function Parameters
- `source`: Data source selection
- `hf_config`: HuggingFace dataset config (if needed)
- `imb_factor`: Imbalance factor cho torchvision source
- `seed`: Reproducibility seed

## âš–ï¸ Re-weighting Formula

```python
# Train distribution
p_train = counts_train / counts_train.sum()

# Test distribution (balanced)  
p_test = counts_test / counts_test.sum()

# Re-weight factors
w_class = p_train / p_test  # [C]

# Sample weights
w_sample = w_class[labels]  # [N]
```

Äiá»u nÃ y Ä‘áº£m báº£o model Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ fair trÃªn test set balanced báº±ng cÃ¡ch re-weight theo train distribution.

## ğŸ§ª Testing

Táº¥t cáº£ functions Ä‘Ã£ Ä‘Æ°á»£c test vá»›i comprehensive test suite trong `tests/data/test_dataset.py`.

## ğŸ“ Notes

- Paper mode khÃ¡c vá»›i original splits á»Ÿ viá»‡c VAL/TEST tá»« original test set thay vÃ¬ train set
- Re-weighting giÃºp Ä‘Ã¡nh giÃ¡ model performance trÃªn balanced data nhÆ°ng theo train distribution  
- Class grouping theo threshold=20 samples phÃ¹ há»£p cho research comparison
- HuggingFace integration cho reproducibility vá»›i datasets cÃ³ sáºµn