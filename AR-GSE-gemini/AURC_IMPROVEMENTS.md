# AURC Improvement Patches

## Váº¥n Ä‘á» chÃ­nh
**AURC khÃ´ng cáº£i thiá»‡n vÃ¬ ranking cá»§a margins khÃ´ng Ä‘á»•i.** Recalibrate threshold chá»‰ dá»‹ch Ä‘iá»ƒm cáº¯t, khÃ´ng thay Ä‘á»•i thá»© tá»±.

## CÃ¡c báº£n vÃ¡ Ä‘Ã£ implement

### âœ… 1. Äá»“ng bá»™ per-expert temperature (CRITICAL)
**File: `eval_gse_plugin.py`**
- âœ… `get_mixture_posteriors()` Ä‘Ã£ Ã¡p dá»¥ng temperature scaling
- âœ… `recalibrate_thresholds_on_val()` Ä‘Ã£ Ã¡p dá»¥ng temperature scaling
- âœ… Consistency: train vÃ  eval sá»­ dá»¥ng cÃ¹ng phÃ¢n bá»‘

**Impact:** Temperature scaling thay Ä‘á»•i ranking cá»§a margins â†’ áº£nh hÆ°á»Ÿng trá»±c tiáº¿p AURC

---

### âœ… 2. Fix alpha update trong inner loop (CRITICAL)
**File: `gse_worst_eg.py`**

**Váº¥n Ä‘á» cÅ©:**
```python
# Placeholder - alpha khÃ´ng thá»±c sá»± update
a_cur = 0.9 * a_cur + 0.1 * torch.ones(K, device=device)
```

**Giáº£i phÃ¡p:**
```python
# New helper function
def update_alpha_conditional_with_beta_tgroup(eta, y, alpha, mu, beta, t_group, ...):
    """Conditional alpha update with beta weighting and per-group thresholds"""
    # 1. Compute raw margins with beta
    # 2. Get predictions with (Î±*Î²) weighting
    # 3. Use PREDICTED group for threshold (deployable)
    # 4. Compute acceptance per GT-group (training signal)
    # 5. EMA update with projection (geomean=1, clamp [0.8, 1.4])
    
# Usage in inner loop
a_cur = update_alpha_conditional_with_beta_tgroup(
    eta_S1, y_S1, a_cur, mu, beta, t_group_cur, class_to_group, K,
    gamma=gamma, a_min=0.8, a_max=1.4
)
```

**Impact:** 
- Î± thá»±c sá»± di chuyá»ƒn (khÃ´ng cÃ²n káº¹t á»Ÿ [1, 1])
- Ranking cá»§a margins thay Ä‘á»•i theo má»¥c tiÃªu coverage/group
- AURC giáº£m Ä‘Ã¡ng ká»ƒ

---

### âœ… 3. Fit t_k theo pred-group trÃªn ALL predictions
**File: `gse_worst_eg.py`**

**Váº¥n Ä‘á» cÅ©:**
```python
# Fit trÃªn correct-only vá»›i GT-groups
correct_mask = (preds_S1 == y_S1.cpu())
t_group_cur = fit_group_thresholds_from_raw(
    raw_S1.cpu()[correct_mask], 
    y_groups_S1[correct_mask], ...
)
```

**Giáº£i phÃ¡p:**
```python
# Fit trÃªn ALL predictions vá»›i PREDICTED groups (deployable)
alpha_per_class = (a_cur * beta)[class_to_group]
yhat_S1 = (alpha_per_class.unsqueeze(0) * eta_S1).argmax(dim=1).cpu()
pred_groups_S1 = class_to_group[yhat_S1]

t_group_cur = []
for k in range(K):
    mk = (pred_groups_S1 == k)
    if mk.sum() > 0:
        q = 1.0 - target_cov_by_group[k]
        t_k = float(torch.quantile(raw_S1[mk].cpu(), q))
        t_group_cur.append(t_k)
```

**Impact:**
- Thresholds Ä‘Ã£ "deployable" ngay trong training
- Giáº£m lá»‡ch train-eval
- Coverage á»•n Ä‘á»‹nh hÆ¡n

---

### âœ… 4. Coverage penalty trong objective
**File: `gse_worst_eg.py`**

**ThÃªm vÃ o evaluation:**
```python
# Compute coverage by predicted groups on S2
raw_S2 = compute_raw_margin_with_beta(eta_S2, a_cur, mu, beta, class_to_group)
yhat_S2 = (alpha_per_class_S2.unsqueeze(0) * eta_S2).argmax(dim=1)
pred_groups_S2 = class_to_group[yhat_S2]

# Per-group coverage
cov_by_pred_group = []
for k in range(K):
    mk = (pred_groups_S2 == k)
    cov_k = (raw_S2[mk] >= t_group_cur[k]).float().mean().item()
    cov_by_pred_group.append(cov_k)

# Coverage penalty
cov_penalty = sum((cov_by_pred_group[k] - target_cov_by_group[k])**2 for k in range(K))

# Combined objective
score = w_err + 5.0 * cov_penalty  # weight 5.0
```

**Impact:**
- EG-outer khÃ´ng Ä‘Ã¡nh Ä‘á»•i worst-error báº±ng threshold quÃ¡ kháº¯t
- Coverage giá»¯ á»•n Ä‘á»‹nh gáº§n target
- TrÃ¡nh overfitting trÃªn S2

---

### âœ… 5. Ná»›i range Î± vÃ  tÄƒng alpha_steps
**Files: `gse_balanced_plugin.py`, `gse_worst_eg.py`**

**Thay Ä‘á»•i:**
```python
# Old bounds
'alpha_min': 0.85, 'alpha_max': 1.15, 'alpha_steps': 5

# New bounds (more room for head/tail adjustment)
'alpha_min': 0.80, 'alpha_max': 1.40, 'alpha_steps': 7
```

**Impact:**
- Î± cÃ³ dÆ° Ä‘á»‹a cÃ¢n báº±ng head/tail
- Î¼ khÃ´ng pháº£i "gÃ¡nh" háº¿t (Î¼ hiá»‡n Â±0.51 khÃ¡ lá»›n)
- Ranking linh hoáº¡t hÆ¡n

---

## Ká»³ vá»ng sau patches

### Coverage metrics:
- âœ… Coverage tá»•ng â‰ˆ 0.5-0.6 (gáº§n target Ï„_head=0.56, Ï„_tail=0.44)
- âœ… Per-group coverage á»•n Ä‘á»‹nh

### AURC metrics:
- âœ… AURC (Balanced) giáº£m â‰¥ 5-10%
- âœ… AURC (Worst) giáº£m â‰¥ 10-15%
- âœ… RC curve mÆ°á»£t hÆ¡n, khÃ´ng cÃ³ "sá»¥t Ä‘á»™t ngá»™t"

### Alpha evolution:
- âœ… Î± khÃ´ng cÃ²n káº¹t á»Ÿ [1, 1]
- âœ… Î± di chuyá»ƒn trong range [0.8, 1.4]
- âœ… Log sáº½ hiá»ƒn thá»‹: `Î±_t = [0.92, 1.08]` (example)

### Training logs:
```
EG iteration 5/20, Î²=[0.4500, 0.5500]
   Î±_t = [0.9234, 1.0812], Î¼_t = [0.3200, -0.3200]
   t_group = [-0.6520, -0.5950]

âœ… Best inner solution: score=0.0518 (raw_err=0.0485, cov_pen=0.0066)
```

---

## Tuá»³ chá»n nÃ¢ng cao (chÆ°a implement)

### Option A: Fine-tune gating vá»›i ranking-aware loss
```python
# After getting Î±*, Î¼*, t_k* from EG-outer
# Fine-tune gating_net 3-5 epochs with:

L_sel = E[s(x) Â· CE(q_Î±, y)]  # Selective CE
L_bce = BCEWithLogits(Îº(m_raw - t_{g(y)}), 1{y=Å·})  # Acceptance BCE
L_kl = KL(w(x) || prior_group)  # Group prior

L_total = L_sel + Î»_bce * L_bce + Î»_kl * L_kl
```

**Impact:** Äá»•i trá»±c tiáº¿p w(x) â†’ Î·(x) â†’ ranking cá»§a margins â†’ AURC â†“â†“

---

## Testing checklist

- [ ] Run training: `python run_improved_eg_outer.py`
- [ ] Check alpha evolution in logs (should move from [1, 1])
- [ ] Check coverage penalty in logs (should be < 0.01)
- [ ] Run evaluation: `python -m src.train.eval_gse_plugin`
- [ ] Compare AURC before/after (expect â‰¥10% reduction)
- [ ] Verify coverage hits target (0.56 head, 0.44 tail)
- [ ] Check RC curve smoothness (no sudden drops)

---

## Files modified

1. `src/train/gse_worst_eg.py`
   - Added `update_alpha_conditional_with_beta_tgroup()`
   - Updated threshold fitting (pred-group, ALL samples)
   - Added coverage penalty to objective
   - Enhanced logging for alpha tracking

2. `src/train/gse_balanced_plugin.py`
   - Updated CONFIG: alpha_min=0.80, alpha_max=1.40, alpha_steps=7
   - Updated all alpha update functions with new bounds
   - Temperature scaling already present in `cache_eta_mix()`

3. `src/train/eval_gse_plugin.py`
   - Temperature scaling already consistent
   - Recalibration uses predicted groups
   - Ready for improved AURC measurement

---

## Debug tips

If Î± still doesn't move:
```python
# In inner loop, add print:
print(f"  [DEBUG] alpha before: {a_cur.tolist()}")
a_cur = update_alpha_conditional_with_beta_tgroup(...)
print(f"  [DEBUG] alpha after:  {a_cur.tolist()}")
print(f"  [DEBUG] alpha_hat:    {alpha_hat.tolist()}")
```

If AURC doesn't improve:
- Check temperature is applied consistently (train & eval)
- Check margins_raw are computed with same Î±, Î¼, T
- Verify ranking changes: plot sorted margins before/after
- Compare RC curves visually

---

## Next steps

1. **Run training** and check logs for alpha movement
2. **Evaluate** and compare AURC metrics
3. **If still not satisfactory:** Consider fine-tune gating (Option A)
4. **Document results** in results/ folder
5. **Commit changes** with clear message

---

**Expected timeline:**
- Training: ~2-3 hours
- Evaluation: ~10 minutes
- Analysis: ~30 minutes
- **Total: 3-4 hours for complete cycle**

Good luck! ğŸš€
