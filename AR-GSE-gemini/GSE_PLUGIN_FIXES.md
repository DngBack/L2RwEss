# GSE Balanced Plugin Fixes - Deployable Decision Rule

## NgÃ y: 30/09/2025

## Tá»•ng quan
ÄÃ£ kháº¯c phá»¥c cÃ¡c váº¥n Ä‘á» lá»‡ch chuáº©n quan trá»ng trong `gse_balanced_plugin.py` Ä‘á»ƒ Ä‘áº£m báº£o luáº­t quyáº¿t Ä‘á»‹nh **kháº£ triá»ƒn (deployable)** vÃ  nháº¥t quÃ¡n vá»›i paper AR-GSE.

---

## âœ… CÃ¡c váº¥n Ä‘á» Ä‘Ã£ sá»­a

### 1. **NgÆ°á»¡ng theo nhÃ³m cá»§a Å· (khÃ´ng pháº£i y_true)** ğŸ¯

**Váº¥n Ä‘á»**: 
- `worst_error_on_S_with_per_group_thresholds()` dÃ¹ng `t_group[y_groups]` vá»›i `y_groups = class_to_group[y]`
- á» test-time khÃ´ng biáº¿t `y_true`, khÃ´ng thá»ƒ Ã¡p ngÆ°á»¡ng theo ground-truth group

**Giáº£i phÃ¡p**:
```python
# Prediction with Î±
alpha_per_class = alpha[class_to_group]  # [C]
yhat = (alpha_per_class.unsqueeze(0) * eta).argmax(dim=1)  # [N]

# Threshold based on PREDICTED group (deployable!)
pred_groups = class_to_group[yhat]  # [N]
thresholds_per_sample = t_group[pred_groups]  # [N]

# Hard acceptance
accepted = (raw_margins > thresholds_per_sample)
```

**LÃ½ do**: Luáº­t quyáº¿t Ä‘á»‹nh pháº£i dá»±a vÃ o Å· Ä‘á»ƒ triá»ƒn khai Ä‘Æ°á»£c á»Ÿ test-time (khÃ´ng biáº¿t y tháº­t).

---

### 2. **Per-Expert Temperature Scaling** ğŸŒ¡ï¸

**Váº¥n Ä‘á»**: 
- `cache_eta_mix()` tÃ­nh `softmax(logits)` trá»±c tiáº¿p, bá» qua temperature calibration
- Margin/threshold khÃ´ng á»•n Ä‘á»‹nh náº¿u experts chÆ°a calibrated

**Giáº£i phÃ¡p**:
```python
def apply_per_expert_temperature(logits, expert_names, temp_dict):
    """Apply T_e to each expert e before softmax"""
    if not temp_dict:
        return logits
    scaled = logits.clone()
    for i, name in enumerate(expert_names):
        T = float(temp_dict.get(name, 1.0))
        if abs(T - 1.0) > 1e-6:
            scaled[:, i, :] = scaled[:, i, :] / T
    return scaled

# In cache_eta_mix:
logits = apply_per_expert_temperature(logits, expert_names, temperatures)
expert_posteriors = torch.softmax(logits, dim=-1)
```

**Lá»£i Ã­ch**: Mixture posterior Î·Ìƒ Ä‘Ã£ calibrated â†’ margin/threshold á»•n Ä‘á»‹nh hÆ¡n.

---

### 3. **Alpha Update vá»›i Per-Group Thresholds** ğŸ”„

**Váº¥n Ä‘á»**: 
- CÃ¡c hÃ m update Î± hiá»‡n dÃ¹ng scalar threshold `t`
- Khi cÃ³ per-group thresholds `t_k`, cáº§n update theo luáº­t deployable

**Giáº£i phÃ¡p**: ThÃªm `update_alpha_conditional_pg()`:
```python
def update_alpha_conditional_pg(eta, y, alpha, mu, t_group, class_to_group, K, ...):
    """Conditional alpha update using per-group thresholds (deployable)"""
    
    # Prediction
    alpha_per_class = alpha[class_to_group]
    yhat = (alpha_per_class.unsqueeze(0) * eta).argmax(dim=1)
    
    # Raw margin
    raw = compute_raw_margin(eta, alpha, mu, class_to_group)
    
    # Per-sample threshold based on PREDICTED group
    t_samp = t_group[class_to_group[yhat]]
    
    # Hard acceptance
    accepted = raw > t_samp
    
    # Conditional acceptance per ground-truth group
    y_groups = class_to_group[y]
    alpha_hat = torch.ones_like(alpha)
    for k in range(K):
        mask = (y_groups == k)
        if mask.any():
            acc_rate = (accepted & mask).float().sum() / mask.float().sum()
            alpha_hat[k] = acc_rate + 1e-3
    
    # EMA + project
    new_alpha = (1 - gamma) * alpha + gamma * alpha_hat
    return project_alpha(new_alpha, alpha_min, alpha_max)
```

**Sá»­ dá»¥ng trong inner loop**:
```python
# Blended update for stability
alpha = 0.75 * update_alpha_joint(...) + 0.25 * update_alpha_conditional_pg(...)
```

---

### 4. **Deterministic Training** ğŸ”§

**Váº¥n Ä‘á»**: Random initialization/ordering cÃ³ thá»ƒ gÃ¢y khÃ¡c biá»‡t giá»¯a cÃ¡c láº§n cháº¡y

**Giáº£i phÃ¡p**:
```python
torch.manual_seed(CONFIG['seed'])
np.random.seed(CONFIG['seed'])
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

**Lá»£i Ã­ch**: Reproducible results, dá»… debug vÃ  compare.

---

### 5. **Load Temperatures tá»« Selective Checkpoint** ğŸ“‚

**Váº¥n Ä‘á»**: Selective training Ä‘Ã£ fit temperatures, nhÆ°ng plugin khÃ´ng dÃ¹ng

**Giáº£i phÃ¡p**:
```python
# When loading selective checkpoint
temperatures = sel_ckpt.get('temperatures', None)
if temperatures:
    print(f"âœ… Loaded per-expert temperatures: {temperatures}")

# Apply when caching
eta_S1, y_S1 = cache_eta_mix(model, S1_loader, class_to_group,
                              expert_names=CONFIG['experts']['names'],
                              temperatures=temperatures)
```

---

## ğŸ¯ CÃ´ng thá»©c Chuáº©n (Paper-Consistent)

### Dá»± Ä‘oÃ¡n:
```
Å· = argmax_y Î±_{g(y)} * Î·Ìƒ_y(x)
```

### Acceptance (Per-Group Thresholds):
```
accept âŸº m_raw(x) > t_{g(Å·)}
```
**Quan trá»ng**: NgÆ°á»¡ng dá»±a vÃ o `g(Å·)` (predicted group), khÃ´ng pháº£i `g(y)` (true group)!

### Raw Margin:
```
m_raw(x) = max_y Î±_{g(y)} * Î·_y - Î£_y (1/Î±_{g(y)} - Î¼_{g(y)}) * Î·_y
```

### Conditional Acceptance Rate:
```
rÌ‚_k = P(accept | y âˆˆ G_k) = #{accept âˆ§ yâˆˆG_k} / #{yâˆˆG_k}
```

---

## ğŸ“Š CÃ¡c váº¥n Ä‘á» chÆ°a sá»­a (TODO)

### ğŸ”´ Quan trá»ng: Bá» Î² khá»i Inner Rule (EG-Outer)

**Váº¥n Ä‘á» hiá»‡n táº¡i** (trong EG-outer code):
```python
# âŒ WRONG: Î² Ä‘Æ°á»£c nhÃ¢n vÃ o rule
preds = ((alpha * beta)[class_to_group] * eta).argmax(...)
raw = compute_raw_margin_with_beta(eta, alpha, mu, beta, ...)
```

**Sá»­a Ä‘Ãºng**:
```python
# âœ… CORRECT: Î² chá»‰ dÃ¹ng cho objective, khÃ´ng can thiá»‡p rule
preds = (alpha[class_to_group] * eta).argmax(...)  # No Î²
raw = compute_raw_margin(eta, alpha, mu, ...)       # No Î²

# Î² chá»‰ dÃ¹ng Ä‘á»ƒ weight objective trong outer loop
weighted_errors = beta * group_errors
```

**LÃ½ do**: Î² lÃ  trá»ng sá»‘ hÃ³a má»¥c tiÃªu (outer), khÃ´ng pháº£i tham sá»‘ cá»§a luáº­t dá»± Ä‘oÃ¡n/acceptance.

---

### ğŸ”´ Alpha Update trong Inner EG

**Váº¥n Ä‘á»**: Placeholder update thay vÃ¬ blended conditional:
```python
# âŒ Current
a_cur = 0.9 * a_cur + 0.1 * torch.ones(K)
```

**Sá»­a Ä‘Ãºng**: DÃ¹ng `update_alpha_conditional_pg()` vá»›i per-group thresholds.

---

### ğŸŸ¡ Self-Import

**Váº¥n Ä‘á»**: 
```python
from src.train.gse_balanced_plugin import worst_error_on_S_with_per_group_thresholds
```
trong chÃ­nh file `gse_balanced_plugin.py` â†’ circular import risk.

**Sá»­a**: Gá»i hÃ m trá»±c tiáº¿p, khÃ´ng import.

---

### ğŸŸ¡ Äá»•i tÃªn "c" â†’ "t"

**Váº¥n Ä‘á»**: TÃªn biáº¿n `c` gÃ¢y nháº§m vá»›i "rejection cost", thá»±c táº¿ lÃ  threshold `t`.

**Sá»­a**: Äá»•i `compute_margin(eta, alpha, mu, c, ...)` â†’ `compute_margin(eta, alpha, mu, t, ...)`.

---

## ğŸ§ª Testing Checklist

### âœ… Verification Tests:

1. **Prediction law**:
```python
alpha_per_class = alpha[class_to_group]
yhat_expected = (alpha_per_class.unsqueeze(0) * eta).argmax(dim=1)
assert (yhat == yhat_expected).all()
```

2. **Acceptance by pred-group**:
```python
pred_groups = class_to_group[yhat]
t_samp = t_group[pred_groups]
accepted_expected = raw_margins > t_samp
assert (accepted == accepted_expected).all()
```

3. **Temperature scaling**:
```python
# Check if temperatures applied before softmax
scaled = apply_per_expert_temperature(logits, names, temps)
assert not torch.equal(scaled, logits) if temps else torch.equal(scaled, logits)
```

4. **Determinism**:
```bash
# Run twice with same seed
python src/train/gse_balanced_plugin.py
# Results should be identical
```

---

## ğŸ“ˆ Expected Improvements

### Performance:
- âœ… Better tail accuracy (thresholds matched to pred-group)
- âœ… More stable training (temperature scaling)
- âœ… Reproducible results (deterministic mode)

### Consistency:
- âœ… Training/eval match test-time law
- âœ… No mismatch between inner/outer optimization
- âœ… Deployable decision rule (no access to y_true)

---

## ğŸ”§ Usage

### Basic run:
```bash
python src/train/gse_balanced_plugin.py
```

### With selective init (recommended):
```python
CONFIG['plugin_params']['use_selective_init'] = True  # Load gating + temperatures
```

### Check temperatures loaded:
```
ğŸ“‚ Loaded selective gating checkpoint: ...
âœ… Loaded per-expert temperatures: {'ce_baseline': 1.05, 'logitadjust_baseline': 1.12, ...}
ğŸŒ¡ï¸  Applying per-expert temperature scaling: {...}
```

---

## ğŸ“š References

- **Paper**: AR-GSE Section 2.5 (Selective Prediction)
- **Related Fix**: `SELECTIVE_TRAINING_FIXES.md` (train_gating_only.py)
- **Original Issue**: Threshold by ground-truth group â†’ not deployable

---

## ğŸ“ Key Lessons

1. **Test-time Deployability**: Má»i luáº­t quyáº¿t Ä‘á»‹nh pháº£i chá»‰ dá»±a vÃ o input x vÃ  prediction Å·, khÃ´ng Ä‘Æ°á»£c dÃ¹ng y_true.

2. **Consistency is King**: Training/eval/test pháº£i dÃ¹ng cÃ¹ng má»™t luáº­t - khÃ´ng Ä‘Æ°á»£c mismatch giá»¯a cÃ¡c giai Ä‘oáº¡n.

3. **Temperature Matters**: Calibration trÆ°á»›c khi ensemble â†’ mixture posterior á»•n Ä‘á»‹nh hÆ¡n.

4. **Determinism for Science**: Reproducibility lÃ  Ä‘iá»u kiá»‡n cáº§n Ä‘á»ƒ debug vÃ  so sÃ¡nh methods.

5. **Î² is Outer Weight, Not Inner Rule**: Trá»ng sá»‘ hÃ³a objective â‰  can thiá»‡p vÃ o prediction/acceptance rule.

---

## ğŸ“ Files Modified

- `src/train/gse_balanced_plugin.py`:
  - âœ… Added: `apply_per_expert_temperature()`
  - âœ… Added: `update_alpha_conditional_pg()`
  - âœ… Fixed: `worst_error_on_S_with_per_group_thresholds()` (pred-group thresholds)
  - âœ… Fixed: `cache_eta_mix()` (temperature scaling support)
  - âœ… Fixed: `main()` (deterministic mode, load temperatures)

---

## ğŸš€ Next Steps

1. âœ… **Immediate**: Test vá»›i selective checkpoint cÃ³ temperatures
2. ğŸ”´ **High Priority**: Fix EG-outer inner loop (bá» Î² khá»i rule)
3. ğŸŸ¡ **Medium**: Refactor naming (c â†’ t)
4. ğŸŸ¢ **Low**: Add diagnostic logging (per-group coverage by pred-group)
